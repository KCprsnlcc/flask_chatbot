# Chatbot System

## Overview

This project implements a conversational chatbot application designed to offer empathetic and supportive responses to users. The system leverages natural language processing, machine learning, and a Flask web interface to provide a smooth and interactive dialogue experience. The application consists of two main components:

- **Model Training:** A script (`train_model.py`) that processes intent data, trains a neural network model using TensorFlow/Keras, and saves the trained model along with necessary preprocessing data.
- **Web Application:** A Flask-based server (`app.py`) that loads the trained model and associated resources to power the chatbot’s conversational interface.

## Features

- **Intent Recognition:** Combines pre-defined intents (from `intents.json`) with additional entries sourced from the Hugging Face *Empathetic Dialogues* dataset.
- **Natural Language Processing:** Uses NLTK for tokenizing and lemmatizing user inputs.
- **Neural Network Model:** Utilizes a sequential model architecture with dropout layers to enhance performance and generalization.
- **Flask Web Interface:** Provides a responsive chat interface with real-time messaging, including a typing indicator and a minimum response delay to simulate natural conversation.
- **Customizable Responses:** Offers supportive replies tailored to topics like greetings, mental health, self-reflection, and emotional resilience.

## Directory Structure

Below is an overview of the key files and directories in the project:

```
├── __pycache__                    # Python cache files
├── .venv/                         # Virtual environment and its subdirectories
├── static/
│   └── style.css                  # Stylesheet for the web interface
├── templates/
│   └── index.html                 # HTML template for the chatbot interface
├── .gitignore                     # Git ignore file
├── app.py                         # Flask web application
├── chatbot_model.h5               # Trained chatbot model (generated)
├── classes.pkl                    # Pickled classes list (generated)
├── flask_chatbot.code-workspace   # Workspace configuration file
├── intents.json                   # Primary intents definition
├── intents_merged.json            # Merged intents file (generated by training)
├── train_model.py                 # Script to train the chatbot model
└── words.pkl                      # Pickled vocabulary (generated)
```

## Setup and Installation

1. **Clone the Repository**

   ```bash
   git clone https://github.com/KCprsnlcc/flask_chatbot.git
   cd flask_chatbot
   ```

2. **Create and Activate a Virtual Environment**

   ```bash
   python -m venv .venv
   source .venv/bin/activate   # For Windows: .venv\Scripts\activate
   ```

3. **Install Dependencies**

   Install the required Python libraries. If a `requirements.txt` file is available, run:

   ```bash
   pip install -r requirements.txt
   ```

   *If no `requirements.txt` is provided, ensure that you have the following packages installed:*
   
   - Flask
   - nltk
   - numpy
   - tensorflow
   - (Other standard libraries such as `os`, `json`, `logging`, etc., are included in Python.)

4. **Download NLTK Data**

   The scripts automatically download the required NLTK data packages (`punkt` and `wordnet`) during execution.

## Training the Model

Before running the web application, train the chatbot model by executing:

```bash
python train_model.py
```

The training script performs the following tasks:

- Loads primary intents from `intents.json`.
- Augments intents with additional data from the Hugging Face *Empathetic Dialogues* dataset.
- Tokenizes and lemmatizes text data using NLTK.
- Constructs and trains a neural network model using TensorFlow/Keras.
- Saves the trained model (`chatbot_model.h5`), vocabulary (`words.pkl`), class labels (`classes.pkl`), and merged intents (`intents_merged.json`).

## Running the Application

Once the model is trained, start the Flask web application with:

```bash
python app.py
```

The application will run in debug mode by default and can be accessed at:

```
http://localhost:5000
```

## How It Works

- **User Interaction:**  
  Users interact with the chatbot via a web interface defined in `templates/index.html`. Messages are sent asynchronously to the `/get_response` endpoint using JavaScript.

- **Message Processing:**  
  Upon receiving a user message, the server:
  - Tokenizes and lemmatizes the input.
  - Converts the text into a bag-of-words representation.
  - Predicts the most relevant intent using the trained model.
  - Selects an appropriate response from the merged intents dataset.

- **Response Simulation:**  
  A typing indicator is displayed to simulate a natural conversation, ensuring a minimum delay (approximately 2 seconds) before the bot's response is shown.

## Customization

- **Modifying Intents:**  
  You can edit `intents.json` to add or modify the intents, patterns, and responses. Rerun `train_model.py` after making changes to update the model's training data.

- **Tuning the Model:**  
  Adjust the parameters in `train_model.py` (such as the number of epochs, batch size, or neural network architecture) to optimize model performance.

- **UI Customization:**  
  Update the HTML template (`templates/index.html`) and CSS styles (`static/style.css`) to alter the look and feel of the chatbot interface.

## Troubleshooting

- **Model Loading Issues:**  
  Ensure that `train_model.py` has been executed successfully and that the files `chatbot_model.h5`, `words.pkl`, and `classes.pkl` exist in the project directory.

- **Intents File Errors:**  
  Confirm that `intents.json` is correctly formatted and accessible.

- **Dependency Problems:**  
  Verify that all required packages are installed in your virtual environment.

## Contributing

Contributions are welcome. If you have suggestions or improvements, please submit an issue or pull request via the project's GitHub repository.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **Hugging Face Empathetic Dialogues Dataset:** Provided valuable additional conversational data.
- **NLTK and TensorFlow:** Essential libraries that power the natural language processing and machine learning aspects of the system.
- **Open-Source Community:** For the continuous development and maintenance of the tools and libraries used in this project.

---

Feel free to reach out if you have any questions or require further assistance with the project.